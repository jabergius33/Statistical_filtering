{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "import collections\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# Local imports\n",
    "from filters import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input function\n",
    "def read_kitty(bin_file_name:str, label_file_name:str=None):\n",
    "    \"opens a point cloud frame following kitty formatting\"\n",
    "    with open(bin_file_name, mode='rb') as file:\n",
    "        scan = np.fromfile(file, dtype=np.float32)\n",
    "        scan = np.reshape(scan, (-1,4))\n",
    "        \n",
    "    if label_file_name:\n",
    "        with open(label_file_name, mode='rb') as file:\n",
    "            label = np.fromfile(file, dtype=np.int16)\n",
    "            label = np.reshape(label, (-1,2))\n",
    "        #print('l-size:',label.shape[0], 'p-size:',scan.shape[0])\n",
    "        assert label.shape[0] == scan.shape[0] # assert 1 to 1 ratio\n",
    "        return scan, label\n",
    "    return scan\n",
    "\n",
    "# output function\n",
    "def write_kitty(folder_name:str, dataframes, labels=None, names=None):\n",
    "    \"writes numpy point cloud data as kitty format\"\n",
    "    names = names if names else [str(i) for i in range(len(dataframes))]\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(os.path.join(folder_name))\n",
    "        os.mkdir(os.path.join(folder_name, 'velodyne'))\n",
    "        os.mkdir(os.path.join(folder_name, 'labels'))\n",
    "        \n",
    "    # make velodyne data\n",
    "    vel_dir = os.path.join(folder_name, 'velodyne')\n",
    "    for data, name in zip(dataframes, names):\n",
    "        data.tofile(f'{vel_dir}/{name}.bin', sep='', format='%s')\n",
    "    \n",
    "    # make label data\n",
    "    if labels:\n",
    "        lab_dir = os.path.join(folder_name, 'labels')\n",
    "        for data, name in zip(labels, names):\n",
    "            data.tofile(f'{lab_dir}/{name}.label', sep='', format='%s')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import *\n",
    "from numpy import linalg as LA\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "import time\n",
    "\n",
    "total_time=0\n",
    "total_frames=0\n",
    "execution_time = []\n",
    "\n",
    "\n",
    "dictionary ={} #store the result of each algorithm\n",
    "main_folder = 'sequences' #dataset binary labels\n",
    "outlier_labels = [1] #1 :snow\n",
    "\n",
    "\n",
    "for alg in ['DSOR','DROR' ,'LIOR','DSOR_and_LIOR', 'DROR_and_LIOR']:     \n",
    "\n",
    "\n",
    "    y_true = None    \n",
    "    y_pred = None    \n",
    "    \n",
    "    for inp in ['30','34','35','36','76' ]: #test data\n",
    "\n",
    "        # Get all datapaths\n",
    "        Input_folder = os.path.join(main_folder, inp)\n",
    "        scan_path = os.path.join(Input_folder, 'velodyne')\n",
    "        label_path = os.path.join(Input_folder, 'labels')\n",
    "\n",
    "\n",
    "        scan_names = sorted([os.path.join(dp, f) \n",
    "                  for dp, dn, fn in os.walk(os.path.expanduser(scan_path)) \n",
    "                  for f in fn])\n",
    "\n",
    "        label_names = sorted([os.path.join(dp, f) \n",
    "                   for dp, dn, fn in os.walk(os.path.expanduser(label_path)) \n",
    "                   for f in fn])\n",
    "\n",
    "        #assert all files have corresponding labels\n",
    "        scan_path_len = len(scan_path)+1\n",
    "        label_path_len = len(label_path)+1\n",
    "        names = [scan[scan_path_len:-4] for scan in scan_names]\n",
    "        assert all(name == label[label_path_len:-6] for name, label in zip(names, label_names))\n",
    "\n",
    "        \n",
    "        for scan, label in zip(scan_names, label_names):\n",
    "           \n",
    "\n",
    "            points, labels = read_kitty(scan, label)  #fetch the data point cloud \n",
    "            binary_labels = np.isin(labels[:,0], outlier_labels) # Labels \n",
    "                \n",
    "            end = time.time()\n",
    "            if 'DSOR_and_LIOR' == alg:\n",
    "                end = time.time()\n",
    "                mask = DSOR_and_LIOR(points, 0.05, 4, 288, 0.066, Sfactor=0.04, r=0.08)\n",
    "            elif 'DROR' == alg:\n",
    "                end = time.time()\n",
    "                mask = DROR(points, 0.2, 0.16, 7, 0.08, 20)\n",
    "            elif 'DSOR' == alg:\n",
    "                end = time.time()\n",
    "                mask = DSOR(points, 0.04, 0.08, 4) \n",
    "            elif 'DROR_and_LIOR' == alg:\n",
    "                end = time.time()\n",
    "                mask = DROR_and_LIOR(points, 0.05, 7, 144, 0.066,0.2, 0.16, 0.08, 20 )\n",
    "            elif 'LIOR' == alg:\n",
    "                end = time.time()\n",
    "                mask  = LIOR(points,0.05, 2, 144, 0.066)\n",
    "\n",
    "            frame_time = time.time() - end \n",
    "            total_frames += 1 \n",
    "            execution_time.append(frame_time)\n",
    "            '''  '''\n",
    "            if y_true is None:\n",
    "                y_true = labels[:,0]\n",
    "                y_pred = mask\n",
    "            else:   \n",
    "                y_true = np.concatenate((y_true, labels[:,0]))\n",
    "                y_pred = np.concatenate((y_pred, mask))\n",
    "     \n",
    "    print(\"Mean time:{}\\t std:{}\".format(np.mean(execution_time)))  \n",
    "    \n",
    "    print('filter: ',alg)\n",
    "    dictionary[alg] = f'Precision:{precision_score(y_true, y_pred, average=None)[1]:.5f}\\\n",
    "                      , Recall:{recall_score(y_true, y_pred, average=None)[1]:.5f}\\\n",
    "                      , F1-score:{(f1_score(y_true, y_pred , average=None)[1]):.5f}\\\n",
    "                        '                    \n",
    "'Done!' \n",
    "dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
